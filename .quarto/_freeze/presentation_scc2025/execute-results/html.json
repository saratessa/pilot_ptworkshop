{
  "hash": "a1396e37d176880498f439cd9de51e02",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Developing and Pilot Testing a 5-Week Precision Teaching Workshop\"\nauthor: \"Saratessa Palos MA BCBA LBA and \nDemi Fragale MS BCBA-LBA NY\"\noutput-file: index.html       \nformat:\n  revealjs:\n    theme: [styles.scss]\n    transition: slide\n    footer: \"University of Oregon, College of Education\"\n    logo: logo.png\n    slide-number: true\neditor: visual\n---\n\n\n::: {.cell}\n\n:::\n\n\n## CEU Objectives\n\n<small>\n\nParticipants will be able to\n\n**List** the phases of the Multiphase Optimization Strategy (MOST) framework\n\n**Identify** instructional design principles used in the development of the Precision Teaching workshop</small>\n\n::: notes\nThese are the CEU objectives\n:::\n\n## <small>**Problem Number One**</small>\n\nPT offers a measurement system that improves decision making quality of practitioners\n\nStudies suggest that PT can effectively improve skill acquisition in children with autism, leading to better retention, endurance, stability, and generalization of learned skills <small> (Wolking, 1980; White 2000; Mannion, 2022; Martinho et al., 2022).</small>\n\n::: notes\nThe first motivating problem of my work is that PT gives us a really strong measurement system that helps practitioners make better decisions. We know this from research, precision teachers are more engaged with program data so they make more responsive choices that benefit their clients.\n\nWell how is this a problem? its a problem because even though it’s this powerful system, PT and the use of the Standard Celeration Chart aren’t part of the BACB task list. So, it usually doesn’t get taught in graduate programs. Which means most pre-licensure BCBAs are entering the field without this tool in their training.\n:::\n\n## <small> Problem Number Two</small>\n\nAs a field we have strong research-based and evidence-based instructional strategies but there is a lack of research for these methods in an online setting\n\n## <small>**Gap in The Research**</small>\n\n::: center\n![](image1.png)\n:::\n\n::: notes\nThis visual is meant to show the gap in the research. What you’re looking at are search results from two databases. The yellow bars are guided notes—also called ASR or active student responding—and the green bars are frequency building.\n\n‘A’ is the initial search. ‘B’ is when we narrow it to articles in college or university settings. And ‘C’ is when we add in the online space.\n\nSo you can see, as soon as we get to online instruction, there’s a huge drop-off. There’s really a dearth of research using these kinds of behavioral education methods in online settings.\n\nThere is a clear gap in the research but You might wonder why this is a problem\n:::\n\n## <small>**Why is This a Problem?**</small>\n\n::: center\n![](image2.png)\n:::\n\n::: notes\nthe majority of pre-licensure BCBAs are being trained in online or hybrid masters programs.\n\nSo just a quick note about this data. I want to be clear that this excludes doctoral programs, bachelor’s programs, and master’s programs that are in education or psychology but have a VCS or ABA specialization. What I included here are only programs titled Masters in ABA or Masters in Behavior Analysis.\n\nBecause of that, it’s very possible this number is actually an underestimate.\n\nI pulled the data in two ways—first by looking at the ABAI website for programs with accreditation or seeking accreditation, and then by doing a Google search for ‘ABA master’s programs’ and going about five pages deep, making sure not to double count. And if it wasn’t obvious whether a program was online, hybrid, or in person, I emailed them directly to check.\n\nSo, given all of that, it’s probably conservative. But even so, at least 54% of pre-licensure BCBAs are doing their training online—and yet we have very little in the way of evidence-based instructional strategies designed specifically for that context.\n:::\n\n## **Aims of This Research Line:**\n\n::: center\n![](image18.png)\n:::\n\n::: notes\nIn order to address both of these problems we want to\\\ncreate an optimized and scalable entry level training that can be adopted by online graduate programs or serve as a stand alone module for pre-licensure BCBAs\n\nResearch these strategies in the online context to Learn the independent and interaction effects of these under-researched promising behavioral education strategies for online graduate programs \n\ndemonstrate the use of a validated implementation science framework in the development of training programs for prelicensure BCBA’s \n:::\n\n## \n\n::: center\n![](image3.png)\n:::\n\n::: notes\nThis is the traditional way researchers evaluate a treatment package, this approach can tell you if this package has an effect.\n\nIf were using our entry level training as an example the components that go into this are ASR/Guided notes, a on-page review each week, an application case study, and live coaching which includes frequency building activities.\n\nBut eventhough using this traditional apprpoach to evaluate our workshop can tell us whether or not it has an effect, it cannot tell us 1. Which components are making positive contributions to the outcome 2. Whether the inclusion of one component has an impact on another. \n\nits possible one component could drive the whole effect, and another can be removed for optimization, or the inclusion of one component influences the effectiveness of another. This all matters if we want our workshop to be easily scalable and easily adopted by online masters programs.\n:::\n\n------------------------------------------------------------------------\n\n## <small>**Conceptual Framework of This Research Line**</small>\n\n::: center\n![](image4.png)\n:::\n\n::: notes\nthis is the multiphase optimization strategy (MOST)\n\n\\[walk through the entire flow chart and explain the importance of the continual optimization principle and the resource management principle because those are two points that run throughout each stage and will be highlighted in this talk.\n\nTalk about how from a behavior analysts POV the instructional design and data based decision making will live in the preparation stage and then the optimization stage could be a component analysis. \\]\n\nFollowing the validated implementation science framework, MOST, allows you to first optimize the intervention before evaluating it.\n\noptimizing means achieving a balance of effectiveness against 1. affordability, 2. scalability, and 3. efficiency. The result is interventions that eliminate inactive and unnecessary components, are practical to implement, and offer a good value.\n:::\n\n## <small>**Our Research Line**</small>\n\n::: center\n![](image5.png)\n:::\n\n::: notes\nso this is that MOST framework with our research initiative inside of it. All of the data we are reporting today is from that first preparation stage and will demonstrate how we designed and pilot tested our PT workshop then used the resource management principle and continual optimization principle to refine the design as we gear up for our second pilot study.\n\nThe optimization stage will be the work I conduct for my dissertation which will be a factorial experiment and currently we believe the two factors we will select for intervention will be the ASR (guided notes) and Live coaching (frequency building intervention).\n\n\\\nFollowing that work we will decide if this optimized intervention is expected to be sufficiently effective and if no follow resource management principle and go back in to preparation and if yes we will move on to evaluating \n:::\n\n## <small>Zooming into The Preparation Stage</small>\n\n::: center\n![](image17.png)\n:::\n\n::: notes\nThe rest of this presentation is going to sit in the preparation stage of the MOST framework. I’ll walk through the work we’ve done so far—which has really been a lot of pre-work: designing, sourcing, and adapting materials. Then I’ll talk about how we piloted the workshop, the kinds of measures we collected, and how we used those to make data-informed revisions. And finally, I’ll describe what those revisions look like before we move forward for our second pilot study.\n:::\n\n## <small>**Design of The Workshop**</small>\n\n**Pre-work**\n\n::: center\n![](image6.png)\n:::\n\n::: notes\n**Setting Verbal Fluency Standards:**\n\nWe recruited 3 precision teachers- I asked precision teachers who were trained and skilled but used PT at differtent levels / in different contexts. One was a BCBA who wasn't regularly charting in his practice but works frequently in school knows how to chart fluently and is trained in PT. One was a PhD doing research in precision teaching, and one was a practitioner with 5 years direct precision teaching and coaching other precision teachers.\n\nEach PT-er Viewed 3 SCCs each and I took a 1-min verbal sample of them describing the learning picture and identifying as many elements of the chart as they could\n\nVerbal descriptions were analyzed at two levels:\n\n• Quantitative level or how many elements per minute were listed (this ranged from 13 to 19 on average)\n\n• Descriptive level or what terminology was used, did the PT-ers make judgements on what changes they would program or do any prediction about how the program would progress based on the data they saw\n\nBased on this, we created a rubric to score participants within three ranges beginners (7-10 rubric score) intermediate (11-16 rubric score) and advanced (17-21 rubric score)\n:::\n\n## <small>Online Instruction</small>\n\n::: center\n![](zoomandcanvas.png)\n:::\n\n::: notes\nOur workshop was 100% remote, we used the LMS canvas as well as zoom video conferencing. Each week participants logged onto their canvas course during baseline they logged on and took a weekly quiz, once they entered the workshop they logged on, watched a video lesson, engaged with a case study on the canvas shell, and then attended a scheduled zoom meeting. Were going to go over how the material for this was designed, sourced or adapted.\n:::\n\n## <small>canvas module structure</small>\n\n::: center\n![](updated%20canvas%20modules.png)\n:::\n\n::: notes\nThis is how the canvas layout was set up for each week of the study.\n\nIn the yellow cirlce is week 1 lesson module: this one has a lot more material because there is a lot of instructions included. The first four links are related to the case study which I will describe later. The fifth link is the weekly video lesson which were an average of 30 minutes long. and the sixth link is the slides from the live coaching session.\n\nIn the green circle is week 2 lesson module: this is what the rest of the lessons looked like they just had that weeks video, that weeks case study data, and the PowerPoint that was used during the live session became available after they attended the live session.\n\nSo next were going to go more in detail about the design of each of these elements.\n:::\n\n## <small>**Design of The Workshop**</small>\n\n**Asynchronous Materials: weekly video lessons**\n\n::: center\n![](image7.png)\n:::\n\n:::: notes\n::: center\nWe created five instructional videos, and each one had lessons and activities adapted from *The Precision Teaching Book* by Kubina and Yurich. In each video, we also built in a section that used Direct Instruction scripts from Cancio and Maloney. And to make it interactive, we used Panopto so participants had to respond in the moment rather than just passively watch.\n\nAlong with the videos, we gave students guided notes packets that matched the video scripts—but with key parts left blank. That way, as they watched, they had to fill in the missing pieces, which kept them actively engaged with the content.\n:::\n::::\n\n## <small>**Design of The Workshop**</small>\n\n**Asynchronous Materials: Guided notes and SCCs**\n\n::: center\n![](image9.png)\n:::\n\n::: notes\nEach participant was mailed a guided notes packet which followed the scripts of those \\~30 minute weekly video lessons and they were also given a handful of daily per minute paper charts.\n:::\n\n## <small>**Design of The Workshop**</small>\n\n**Asynchronous Materials: Case study**\n\n::: center\n![](image10.png)\n:::\n\n::: notes\nNow, the case study I talked about earlier. This was an independent application task. Participants were mailed blank standard celeration charts and each week of the workshop they were given data from a “case study client” participants were expected to graph this data on their own without feedback and we would score their completed chart with 5 weeks of data at the end of the study. To create a structured form that would anchor the workshop, and try to ensure skills were applied in authentic context, I first consulted with BCBAs specializing in verbal behavior and created a hypothetical VB-MAPP. Using an AI model, I generated plausible datasets and then refined them with expert clinicians\n:::\n\n## <small>**Synchronous Materials: Structured coaching sessions**</small>\n\n::: center\n![](coaching.png)\n:::\n\n::: notes\nFor the live coaching sessions, we kept a really consistent structure each week. After participants had finished that week’s video lesson and quiz, we’d meet together. I’d start by giving them a one-page review of the video, and then we’d do a quick Q&A where they could bring up any questions or things that weren’t clear.\n\nFrom there, we moved into practice activities—using Melroe’s fluency training materials for chart-reading drills, and Brown’s *Precision Decisions* guide to work through decision-making frameworks. We practiced skills like see/say corrects over errors and see/say timing floors.\n\nAt the end of each session, I’d bring in a real chart donated by a clinician and precision teacher that they hadn’t seen before. Participants were asked to describe the learning picture, and I recorded and transcribed their responses. Those verbal descriptions were later scored using a rubric I developed from earlier pre-work analyzing how experienced precision teachers describe learning pictures.\n:::\n\n## <small>Pilot Study 1</small>\n\n::: center\n![](full%20timeline.png)\n:::\n\n::: notes\nMultiple Baseline Design\n\nParticipants were students in University of Oregon's Applied Behavior Analysis (ABA) Master of Science program.\n\nNine students were recruited for this study, two withdrew to participate in MSI, and 3 more withdrew during baseline.\n\nTotal N = 4 who we randomized into three “groups” so that participants started the PT workshop at different time points\n:::\n\n## <small>**Measures**</small>\n\n• Time to 100% on SCC Quizzes (weekly, Canvas-based)\n\n• Graphing Accuracy (application task scored with a rubric)\n\n• Written Learning Picture Interpretation (weekly written responses that were scored with a rubric)\n\n• Social Validity Survey (end-of-study)\n\n**Fluency Outcomes**\n\na\\) Timing floors\n\nb\\) Corrects/Errors\n\nc\\) Verbal descriptions of a learning picture </small>\n\n::: notes\nWe collected a variety of measures across the study. Each week, participants completed a quiz in Canvas (baseline and 5 weeks of instruction). They were told to re-take the quiz as many times as needed until they reached 100% accuracy. From that, we got two measures: the time it took to reach 100% and the number of attempts. The quiz itself used a donated clinical SCC, and the very first question was always, ‘Describe the learning picture.’ We scored that written response with a rubric, while the remaining questions focused on chart elements and were multiple choice.\n\nAnother measure was graphing accuracy. Each week, participants received client data and notes in Canvas and were told simply to graph it—no instructions or guidance were provided. This was designed as a \"structued form\" or application check. At the end of the study, they were supposed to mail their completed graphs back to us. Spoiler alert: only one person actually mailed theirs in.\n\nFinally, at the very end of the study, participants completed a social validity survey to give their feedback.\n\nOn top of all of that, we tracked fluency outcomes during coaching sessions. These included timing floors, corrects and errors during practice, and verbal descriptions of learning pictures which we scored with the rubrics produced from the prework we did with the precision etachers.\n\nTaken together, these measures gave us a comprehensive picture of both accuracy and fluency across multiple types of tasks.\n:::\n\n## <small>Fluency</small>\n\n**Participant 1B:**\n\n::: center\n![](scc1B.png){fig-align=\"center\" width=\"537\"}\n:::\n\n::: notes\nvisual inspection of 1B data\n:::\n\n## <small>Fluency</small>\n\n**Participant 2A:**\n\n::: center\n![](scc2A.png){fig-align=\"center\" width=\"582\"}\n:::\n\n::: notes\nvisual inspection of 2A\n:::\n\n## <small>Fluency</small>\n\n<small>**Participant 3A:**</small>\n\n::: center\n![](SCC3A.png){fig-align=\"center\" width=\"599\"}\n:::\n\n::: notes\nVisual inspection of 3A\n:::\n\n## <small>Fluency</small>\n\n<small>**Participant 3B:**</small>\n\n::: center\n![](SCC3B.png){fig-align=\"center\" width=\"555\"}\n:::\n\n::: notes\nvisual inspection for 3B\n:::\n\n## changes made? {.inverse background-color=\"#E0E0E0\"}\n\n::: center\n![](change_fluency.png){fig-align=\"center\" width=\"750\"}\n:::\n\n::: notes\n**Resource Management** means Don’t waste time, money, or participant effort, design with feasibility in mind.\n\n**Continual Optimization** means Don’t stop at one version of the intervention, keep making it better.\n\nin terms of resource management I don't think you could get a more resource efficient teaching procedure than a 1 minute timing. This effectively balances effectiveness with feasibility.\n\nIn the early weeks of the study, we were using scanned versions of the Melroe charts. Participants told me they were hard to read in that format, but at the time all I had were paper copies. Because of that, I think we lost some of the power of this one-minute intervention. Even so, we still saw results. For the next iteration, we’re re-creating all of her packet of charts on a digital platform so they’ll be crystal clear from the very first session.\n:::\n\n## <small>Verbal Scores</small>\n\n::: center\n![](image12.png)\n:::\n\n::: notes\nEach participant experienced level change moving from below beginner threshold to intermediate.\n\nKeep as is, no change.\n:::\n\n## changes made? {.inverse background-color=\"#E0E0E0\"}\n\n::: center\n![](change_verbals.png){fig-align=\"center\" width=\"731\"}\n:::\n\n::: notes\n**Resource Management** means Don’t waste time, money, or participant effort, design with feasibility in mind.\n\n**Continual Optimization** means Don’t stop at one version of the intervention, keep making it better.\n\nThis was a really simple way to just continually practice analyzing these charts I think all of our participants got a lot out of it, so this will remain in tact as is in the next iteration of the workshop.\n:::\n\n## <small>Application Check: Case Study</small>\n\n::: center\n![](image13.png)\n:::\n\n::: notes\nout of the four participants, only one actually mailed their chart back. And after quite a few email reminders, we eventually got a second chart scanned to us.\n\nThe logic behind this measure was that they’re going to be watching these videos about the precision teaching process, doing weekly written and visual analyses of completed charts, so this task would be their chance to construct a chart themselves. The idea was that they’d get to watch it build across the weeks, almost like a structured form that prepared them for what it feels like to really be a precision teacher.\n\nBut in practice, probably half of the students completed it no way to know if the other two did. And of those, the charts looked really different even though they had the same data, they picked different parts of the data to graph, they didn’t add notes, and they even skipped filling in labeled blanks. It was obvious this task wasn’t structured enough to get what we wanted to get out of it. Honestly, it wasn’t worth the amount of time it took to make the case study data. So, this measure will definitely be revised going forward.\n:::\n\n## changes made? {.inverse background-color=\"#E0E0E0\"}\n\n::: center\n![](change_casestudy.png){fig-align=\"center\" width=\"695\"}\n:::\n\n::: notes\n**Resource Management** means Don’t waste time, money, or participant effort, design with feasibility in mind.\n\n**Continual Optimization** means Don’t stop at one version of the intervention, keep making it better.\n\n**Major Change:** we’re using R to simulate a learner with hidden math formulas that update based on your chosen strategies, with some randomness added so every group’s learner looks unique.\n\n**a.** Instead of just giving participants data each week with no guidance, they will now be expected to come to the session with that week’s data already graphed.\n\n**b.** At the session, participants will show the instructor their learning picture so far. The instructor will then ask them to make a decision based on their data. From the list of possible decisions, the instructor will simulate the next week’s data to reflect that choice. This means not all participants will have the same dataset—rather, the data will respond to their decisions. This is much more efficient than creating multiple separate five-week data sets.\n\n**c.** In addition to showing their learning picture live, participants will also submit their chart before logging in for the coaching session. This will culminate in a Week 5 “chart share,” where they present their completed chart. That way, the task remains a structured form but also mirrors a common practice in the precision teaching community.\n:::\n\n## <small>Application Check: Case Study</small>\n\n::: center\n![](image16.png)\n:::\n\n::: notes\nHere’s how the case study simulation works.\n\nAt the very top, we have our ‘pretend learner.’ Think of this as a made-up student who has starting skills and makes mistakes in a realistic way. They aren’t a real child, but the computer gives them believable patterns of performance—sometimes better, sometimes worse, with a bit of variability like we’d expect in real life.\n\nWe also built in a set of teaching strategies. Each strategy has rules about what usually happens if you apply it. For example, frequency building usually increases correct responses, error correction reduces mistakes, and adding more opportunities means faster progress.\n\nNow, in practice, this is what you’ll experience as students in the workshop:\n\nFirst, we give you Week 1 data to chart. Everyone starts with the same setup, but the computer adds a bit of randomness so each group’s data looks slightly different.\n\nNext, your group looks at your chart and decides on a teaching strategy to try.\n\nOnce you decide, I run the computer program. In the background, R applies the rules for that strategy and generates a new week of data that reflects your choice.\n\nWe repeat this cycle for five weeks. Each time, you get a new set of data to chart, you make another decision, and the computer updates your learner again.\n\nAt the end, we’ll come together and share the charts, so you can compare how different decisions led to different learning patterns.\n\nSo the simple version is: you chart, you decide, the computer responds with new data.\n:::\n\n## <small>Weekly Quiz</small>\n\n::: center\n![](image14.png){fig-align=\"center\" width=\"798\"}\n:::\n\n::: notes\nThis measure ended up being removed because it didn’t really capture fluency. The quiz format was one open-ended question—‘describe the learning picture’—followed by four multiple-choice questions. Students could retake it until they got 100%.\n\nThe problem was that in baseline, responses were really short, like ‘I don’t know’ or ‘it’s a graph,’ so times looked fast. But as students improved, their answers got longer and more detailed, which actually made completion times slower. So ironically, higher skill inflated the scores. On top of that, students often just guessed on the multiple-choice questions, because thier first attempt would be a few minutes then the next 3 attempts were under a minute so its really clear they werre just selecting responses until they were at 100%.\n:::\n\n## \n\n::: center\n![](image15.png){width=\"1576\"}\n:::\n\n::: notes\nTake away the timing and adding stronger examples in the video lessons including within each video lesson walking though/ verbal model of two clinical charts\n:::\n\n## changes made? {.inverse background-color=\"#E0E0E0\"}\n\n::: center\n![](change_weeklyquizzes.png){fig-align=\"center\" width=\"713\"}\n:::\n\n::: notes\n**Resource Management** means Don’t waste time, money, or participant effort, design with feasibility in mind.\n\n**Continual Optimization** means Don’t stop at one version of the intervention, keep making it better.\n\nThis was a bad measure, the validity of the measure is in question, but also, if were thinking of this in terms of resource management if students aren't even reading the quiz question it is defiantly a waist of time. For the next version, quizzes will be untimed, limited to one attempt, and scored only on written responses using a rubric.\n\nTake away the timing and adding stronger examples in the video lessons including within each video lesson walking though/ verbal model of two clinical charts\n:::\n\n## <small>Social Validity</small>\n\n::: center\n![](image21.png)\n:::\n\n## <small>Social Validity</small>\n\n::: center\n![](image22.png)\n:::\n\n## changes made? {.inverse background-color=\"#E0E0E0\"}\n\n::: center\n![](no change.png){fig-align=\"center\" width=\"687\"}\n:::\n\n::: notes\n**Resource Management** means Don’t waste time, money, or participant effort, design with feasibility in mind.\n\n**Continual Optimization** means Don’t stop at one version of the intervention, keep making it better.\n:::\n\n## <small>Next Steps</small>\n\n::: center\n![](image20.png)\n:::\n\n::: notes\nwhere we’re headed next with this research program.\n\nFirst, we’re going to revise the materials. That means digging deeper into the literature, talking with experienced precision teachers, and really setting clear boundaries for the model in R so it’s solid from the start.\n\nNext, we’ll focus on recruitment. We plan to bring in more graduate students from the UO ABAO program to make sure we have enough participants to run this study well.\n\nThen, in January, we’ll launch the next study as an A–B design. This time, one group will go through all five weeks together. That setup is meant to address the attrition issues we saw in the pilot.\n\nAfter that, we’ll analyze the data with the MOST principles in mind—specifically continual optimization and resource management. In other words, we’ll look not only at whether it worked, but also how to refine and streamline it.\n\nAnd finally, once we’ve learned from this iteration, we’ll move into a full optimization phase where we test combinations of components more systematically.\n\nSo, this next step is really about tightening up what we’ve already built, making it more feasible, and setting ourselves up for the larger optimization trial.\n:::\n\n## <small>Future Directions</small>\n\n<small>\n\n**Short-Term Goal:**Successfully complete the second pilot study to refine materials, procedures, and measures.\n\n**Mid-Term Goal:** Conduct an optimization trail to experimentally evaluate which behavioral education strategies are most effective in online instruction, and how they interact. This will extend beyond PT training to inform the design of evidence-based online ABA education more broadly.\n\n**Long-Term Goal:** Produce a packaged, optimized, and scalable online Precision Teaching workshop that graduate programs can adopt to address the PT training gap for pre-licensure BCBAs. </small>\n\n## **We’d Love Your Feedback!**\n\n<small>Please take a moment to complete our brief feedback survey. </small>\n\n::: center\n![](qrcode.png){fig-align=\"center\"}\n:::\n\n<small>If you use the Standard Celeration Chart (SCC) and have deidentified charts you’d be willing to share as training materials, we’d love your help building our practice library. You can note your interest and leave your email address directly in the survey form.</small>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}